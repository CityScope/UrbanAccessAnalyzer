{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kEAwlkEGTsX"
      },
      "source": [
        "# üöå Accessibility to Public Transport\n",
        "---\n",
        "\n",
        "## üìñ Overview\n",
        "This notebook provides a data-driven framework to evaluate **how easily residents can access public transit services** within a city.\n",
        "\n",
        "By analyzing GTFS (General Transit Feed Specification) schedules and the local street network, we generate an \"Accessibility Score.\" Unlike simple proximity maps, this analysis evaluates the **Level of Service (LoS)** at each stop, accounting for frequency (headway), transit mode (rail vs. bus), and travel speed. \n",
        "\n",
        "---\n",
        "\n",
        "## üìä Evaluation Criteria: Quality & Proximity\n",
        "\n",
        "The analysis uses a multi-dimensional scoring system to determine the final **accessibility** score. We evaluate transit stops based on two main pillars:\n",
        "\n",
        "### 1. Stop Quality\n",
        "A stop's intrinsic quality is determined by:\n",
        "*   **Headway:** How long users have to wait for the next vehicle.\n",
        "*   **Speed:** How fast the transit service moves once on board.\n",
        "*   **Mode:** The perceived \"comfort\" or \"reliability\" factor (e.g., Rail > Tram > Bus).\n",
        "\n",
        "### 2. Walk Proximity\n",
        "\n",
        "### Quality functions \n",
        "\n",
        "To reflect real-world human behavior, we apply **Elasticity** values to our scoring. Elasticity defines the exponential decay of perceived quality as conditions worsen and can be found in common transport economy studies:\n",
        "*   **Headway Elasticity:** As wait times increase, the utility of the stop drops exponentially.\n",
        "*   **Walk Elasticity:** As the walking distance to a stop increases, its accessibility score decreases.\n",
        "*   **Speed Elasticity:** As transit speed increases, the quality of the service improves.\n",
        "\n",
        "**Discretization:** Results are automatically binned into 10 accessibility levels, ranging from 0 (Poor/No Access) to 1 (Excellent Access).\n",
        "\n",
        "<div style=\"display: flex; width: 100%; max-width: 600px; gap: 2px; margin-bottom: 1rem; font-family: sans-serif; font-size: 0.75rem; font-weight: bold;\">\n",
        "  <div style=\"flex:1; background-color:#ff6666; color:white; text-align:center; padding:0.3rem 0;\">0</div>\n",
        "  <div style=\"flex:1; background-color:#ff9999; color:black; text-align:center; padding:0.3rem 0;\">0.1</div>\n",
        "  <div style=\"flex:1; background-color:#ffcc66; color:black; text-align:center; padding:0.3rem 0;\">0.2</div>\n",
        "  <div style=\"flex:1; background-color:#ffff66; color:black; text-align:center; padding:0.3rem 0;\">0.3</div>\n",
        "  <div style=\"flex:1; background-color:#ccff66; color:black; text-align:center; padding:0.3rem 0;\">0.4</div>\n",
        "  <div style=\"flex:1; background-color:#99ff66; color:black; text-align:center; padding:0.3rem 0;\">0.5</div>\n",
        "  <div style=\"flex:1; background-color:#66ff66; color:black; text-align:center; padding:0.3rem 0;\">0.6</div>\n",
        "  <div style=\"flex:1; background-color:#33ff66; color:black; text-align:center; padding:0.3rem 0;\">0.7</div>\n",
        "  <div style=\"flex:1; background-color:#00cc66; color:white; text-align:center; padding:0.3rem 0;\">0.8</div>\n",
        "  <div style=\"flex:1; background-color:#00aa55; color:white; text-align:center; padding:0.3rem 0;\">0.9</div>\n",
        "  <div style=\"flex:1; background-color:#009933; color:white; text-align:center; padding:0.3rem 0;\">1</div>\n",
        "</div>\n",
        "\n",
        "---\n",
        "\n",
        "## üõ†Ô∏è Technical Requirements\n",
        "\n",
        "### üîë API Key Setup\n",
        "This notebook uses the **Mobility Database** to automatically fetch GTFS feeds. \n",
        "1.  Go to [MobilityDatabase.org](https://mobilitydatabase.org/).\n",
        "2.  Create a free account.\n",
        "3.  Navigate to **Account Details** to find your `Refresh Token`.\n",
        "4.  Paste the token in the **Public Transport Data** section below.\n",
        "\n",
        "### üíª Environment\n",
        "To run this analysis, ensure your environment is configured with:\n",
        "> **Core Stack:** `pyGTFSHandler`, `UrbanAccessAnalyzer`, `osmnx`, `geopandas`, `h3`, `polars`  \n",
        "> **System Dependencies:** `osmium-tool` (required for processing large-scale OSM street data)  \n",
        "> **Data Sources:** OpenStreetMap (via Overpass/Geofabrik) and WorldPop (Global 100m population rasters)\n",
        "\n",
        "---\n",
        "\n",
        "*Prepared for use in Google Colab or local Jupyter environments.*\n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DgjJf1ryGRdB"
      },
      "outputs": [],
      "source": [
        "# If using colab\n",
        "# Takes around 2-3 min\n",
        "\n",
        "# !pip install matplotlib mapclassify folium\n",
        "# !apt-get install -y osmium-tool\n",
        "# !pip install \"UrbanAccessAnalyzer[osm,plot,h3] @ git+https://github.com/CityScope/UrbanAccessAnalyzer.git@v1.0.0\"\n",
        "# !pip install \"pyGTFSHandler[osm,plot] @ git+https://github.com/CityScope/pyGTFSHandler.git@v1.0.0\"\n",
        "\n",
        "# Restart notebook after installing this if needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cuKHB4Q3GTL4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from datetime import datetime, date, timedelta, time\n",
        "import pandas as pd\n",
        "import polars as pl\n",
        "import geopandas as gpd\n",
        "from pathlib import Path\n",
        "import zipfile\n",
        "\n",
        "import osmnx as ox\n",
        "\n",
        "import UrbanAccessAnalyzer.isochrones as isochrones\n",
        "import UrbanAccessAnalyzer.graph_processing as graph_processing\n",
        "import UrbanAccessAnalyzer.osm as osm\n",
        "import UrbanAccessAnalyzer.utils as utils\n",
        "import UrbanAccessAnalyzer.h3_utils as h3_utils\n",
        "import UrbanAccessAnalyzer.population as population\n",
        "import UrbanAccessAnalyzer.quality as quality_utils\n",
        "import UrbanAccessAnalyzer.plot_helpers as plot_helpers\n",
        "\n",
        "from pyGTFSHandler.feed import Feed\n",
        "from pyGTFSHandler.downloaders.mobility_database import MobilityDatabaseClient\n",
        "import pyGTFSHandler.plot_helpers as gtfs_plot_helpers\n",
        "import pyGTFSHandler.gtfs_checker as gtfs_checker\n",
        "import pyGTFSHandler.processing_helpers as processing_helpers\n",
        "\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1 Inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### General"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "city_name = \"Cambridge, MA, USA\"\n",
        "\n",
        "# Download area should be larger than the aoi by 'download_buffer' meters\n",
        "# It should be max_walk_distance\n",
        "download_buffer = 1000\n",
        "\n",
        "# Simplify street graph to avoid edges of less than 'min_edge_length'\n",
        "min_edge_length = 30 # in m\n",
        "\n",
        "# If you want results in h3 this is the output h3 resolution\n",
        "h3_resolution = 10 \n",
        "\n",
        "# Do show maps. For large datasets this might break or slow down execution\n",
        "show_maps = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Public transport GTFS timetables\n",
        "\n",
        "**Stop grouping**\n",
        "\n",
        "In GTFS data, bus stops typically have separate `stop_id`s for each direction. Additionally, when multiple routes serve the same physical area, they often use different `stop_id`s as well.\n",
        "\n",
        "To handle this effectively, it makes sense to group nearby stops under a single logical identifier. This is achieved by creating or using the `parent_station` column, which allows related stops to be associated with one parent stop.\n",
        "\n",
        "**Mode** \n",
        "\n",
        "The `route_type` column is mapped to more general transit modes ('bus','tram','rail'). To take better modes into account when adding the effects of multiple routes to the stop headway for 'bus' we include all transit services and for 'tram' we include rail too.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use the stop groups created with arg stop_group_distance in Feed to group neraby stops into one\n",
        "# You could choose 'stop_id' otherwise\n",
        "stop_id = \"parent_station\"\n",
        "# Group near stops (less than x meters apart). This creates or updates the parent_station column\n",
        "stop_group_distance = 100 # in m\n",
        "\n",
        "\n",
        "start_date = datetime.today() # Could be None for min date in feed\n",
        "end_date = start_date + timedelta(days=30) # Could be None for max date in feed\n",
        "date_type='businessday' # Could be something like 'holiday', 'businessday', 'non_businessday', or 'monday' to only consider some dates from the range.\n",
        "start_time = time(hour=8)\n",
        "end_time = time(hour=20) \n",
        "\n",
        "# GTFS contain a column 'route_type' with int values 0-7. \n",
        "# This dict helps grouping all the possible modes in some more general categories.\n",
        "simplified_route_type_mapping = {\n",
        "    'bus':'all',\n",
        "    'tram':[0,1,2,4,5,6,7],\n",
        "    'rail':[1,2]\n",
        "}\n",
        "# -1 - other/nodata\n",
        "# 0 - tram \n",
        "# 1 - subway \n",
        "# 2 - rail \n",
        "# 3 - bus\n",
        "# 4 - ferry \n",
        "# 5 - cable car \n",
        "# 6 - gondola \n",
        "# 7 - funicular"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Quality scoring parameters\n",
        "\n",
        "To turn off (disregard) any contributing parameter to stop quality set its elasticity to 0\n",
        "\n",
        "Elasticities define the exponential curves for how the perceived quality (or demand) drops when headways increase, distance increases or speed decreases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "headway_elasticity = 0.35 # Theoretical value 0.5. In practice from 0.2 (less change) to 0.8 (more change) \n",
        "walk_elasticity = 0.25 # From 0.1 (less change) to 0.5 (more change). Recommended below than 'headway_elasticity'.\n",
        "speed_elasticity = 0.2 # From 0.1 (less change) to 0.5 (more change). Recommended below than 'headway_elasticity'.\n",
        "# Use the same keys as simplified_route_type_mapping\n",
        "# The stop quality score will be multiplied by this factor\n",
        "mode_factor = { \n",
        "    'bus':0.85, # 15% less for bus vs rail. Reasonable values are 0.75-1\n",
        "    'tram':0.92, # 8% less for tram vs rail. Reasonable values are 0.75-1\n",
        "    'rail':1 # Best mode\n",
        "}\n",
        "\n",
        "# Number of discrete quality scores (always in the 0-1 range)\n",
        "n_accessibility_scores = 10\n",
        "\n",
        "# min and max values you want to consider (affects performance and discretization)\n",
        "max_headway = 1440 # in min\n",
        "max_walk_distance = 2000 # in m\n",
        "max_speed = 150 # in km/h \n",
        "\n",
        "min_headway = 5 # in min \n",
        "min_walk_distance = 100 # in m \n",
        "min_speed = 5 # in km/h\n",
        "\n",
        "# Define a combination of params that should achieve a score of 1\n",
        "# and calibrate the quality functions accordingly\n",
        "best_quality = {  # For quality 1\n",
        "    'headway':5,\n",
        "    'mode':'rail',\n",
        "    'speed':30,\n",
        "    'distance':100,\n",
        "}\n",
        "\n",
        "# Define a combination of params that should achieve a score just above 0\n",
        "# and calibrate the quality functions accordingly\n",
        "worst_quality = { # For lowest quality (just above 0)\n",
        "    'headway':720,\n",
        "    'mode':'bus',\n",
        "    'speed':10,\n",
        "    'distance':2000,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9YcUUo1GlAp"
      },
      "source": [
        "### Results folder\n",
        "\n",
        "Where do you want to save the results?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2YhNvRTkGfSg"
      },
      "outputs": [],
      "source": [
        "results_path = os.path.normpath(\"transit\")\n",
        "\n",
        "gtfs_path = os.path.join(results_path,\"gtfs_files\") \n",
        "\n",
        "city_filename = utils.sanitize_filename(city_name)\n",
        "city_results_path = os.path.join(results_path,city_filename)\n",
        "\n",
        "osm_xml_file = os.path.normpath(city_results_path+f\"/streets.osm\")\n",
        "streets_graph_path = os.path.normpath(city_results_path+f\"/streets.graphml\")\n",
        "streets_path = os.path.normpath(city_results_path+f\"/streets.gpkg\")\n",
        "accessibility_streets_path = os.path.normpath(city_results_path+f\"/accessibility_streets.gpkg\")\n",
        "population_results_path = os.path.normpath(city_results_path+f\"/population.gpkg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.makedirs(results_path,exist_ok=True)\n",
        "os.makedirs(gtfs_path,exist_ok=True)\n",
        "os.makedirs(city_results_path,exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Area of interest\n",
        "**Area of interest (aoi)**: Polygon. Geographic area where you want to run your analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Option 1:** From the internet with the city name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "aoi = utils.get_city_geometry(city_name)\n",
        "geo_suggestions = utils.get_geographic_suggestions_from_string(city_name,user_agent=\"app\")\n",
        "geo_suggestions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Option 2:** Load your own file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Geographic file (.gpkg, .geojson or .shp)\n",
        "\n",
        "# aoi = gpd.read_file(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# csv file with lat/lon columns in geographic coordinates\n",
        "\n",
        "\n",
        "# df = pd.read_csv(\"\")\n",
        "\n",
        "\n",
        "# # Create geometry from lon/lat columns\n",
        "# geometry = gpd.points_from_xy(df[\"lon\"], df[\"lat\"]) # Change column names if needed\n",
        "# # Convert to GeoDataFrame\n",
        "# aoi = gpd.GeoDataFrame(\n",
        "#     df,\n",
        "#     geometry=geometry,\n",
        "#     crs=\"EPSG:4326\"  # geographic crs Change if needed\n",
        "# )\n",
        "\n",
        "# # OR Parse WKT geometry column\n",
        "# df[\"geometry\"] = df[\"geometry\"].apply(wkt.loads) # change to match your geometry column name\n",
        "# # Convert to GeoDataFrame\n",
        "# aoi = gpd.GeoDataFrame(\n",
        "#     df,\n",
        "#     geometry=\"geometry\",\n",
        "#     crs=\"EPSG:4326\"  # set to whatever CRS the WKT represents\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use UTM coords and create aoi_download with a buffer of X meters. To avoid boundary effects streets and pois should be downloaded for a larger area."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "aoi = gpd.GeoDataFrame(geometry=[aoi.union_all()],crs=aoi.crs) # Ensure there is only one polygon\n",
        "aoi = aoi.to_crs(aoi.estimate_utm_crs()) # Convert to utm\n",
        "\n",
        "aoi_download = aoi.buffer(download_buffer) # Area to do streets and poi requests "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Public transport data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Option 1** Download GTFS feeds worldwide\n",
        "\n",
        "With the MobilityData API\n",
        "\n",
        "This is the organization responsible for the GTFS standard and has info from almost all the world"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Request your refresh token here: https://mobilitydatabase.org/ \n",
        "# you can find the token under Account Details\n",
        "refresh_token = ''\n",
        "api = MobilityDatabaseClient(refresh_token)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Find Feeds on the API\n",
        "\n",
        "‚ö†Ô∏è Stop here and check that it found your feeds!!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feeds = api.search_gtfs_feeds(\n",
        "    country_code=geo_suggestions['country_codes'],\n",
        "    subdivision_name=geo_suggestions['subdivision_names'], # This info is not always in the feeds metadata. Comment this if you did not find all feeds.\n",
        "    municipality=geo_suggestions['municipalities'], # This info is not always in the feeds metadata. Comment this if you did not find all feeds.\n",
        "    is_official=True, # Set to True if you only want official feeds\n",
        "    #aoi=aoi, # You could comment the rest of search args and use only aoi but for now the API seems to not do this very well as the metadata is often wrong.\n",
        ")\n",
        "\n",
        "for f in feeds:\n",
        "    print(f['provider'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Download current active files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "file_paths = api.download_feeds(\n",
        "    feeds=feeds,\n",
        "    download_folder=gtfs_path,\n",
        "    overwrite=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Option 2** Load your own gtfs files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# file_paths = [\n",
        "#     os.path.normpath(\"/home/miguel/Downloads/latest.zip\"),\n",
        "# ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Unzip if needed\n",
        "# unzipped_paths = []\n",
        "# for p in file_paths:\n",
        "#     path = Path(p)\n",
        "\n",
        "#     # Check if it's a zip file\n",
        "#     if path.is_file() and path.suffix.lower() == \".zip\":\n",
        "#         extract_dir = path.with_suffix(\"\")  # same name, no .zip\n",
        "\n",
        "#         # Extract only if folder doesn't exist\n",
        "#         if not extract_dir.exists():\n",
        "#             with zipfile.ZipFile(path, \"r\") as zip_ref:\n",
        "#                 zip_ref.extractall(extract_dir)\n",
        "\n",
        "#         unzipped_paths.append(str(extract_dir))\n",
        "#     else:\n",
        "#         unzipped_paths.append(str(path))\n",
        "\n",
        "# file_paths = unzipped_paths"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Extra:** Properly check all gtfs files for validity\n",
        "\n",
        "This takes a few minutes. If you skip this step minor validation without logs will be carried out when loading any gtfs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Check and fix the gtfs files (This takes a few minutes). Set check_files = False in Feed to load faster\n",
        "\n",
        "# new_gtfs_path = os.path.join(results_path,\"revised_gtfs_files\") \n",
        "# os.makedirs(new_gtfs_path)\n",
        "\n",
        "# new_file_paths = []\n",
        "# for f in file_paths:\n",
        "#     filename = os.path.splitext(os.path.basename(f))[0]\n",
        "#     if os.path.isdir(os.path.join(new_gtfs_path,filename)):\n",
        "#         new_file_paths.append(os.path.join(new_gtfs_path,filename))\n",
        "#     else:\n",
        "#         new_file_paths.append(gtfs_checker.preprocess_gtfs(f,new_gtfs_path))\n",
        "\n",
        "# file_paths = new_file_paths"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Quality Functions\n",
        "\n",
        "Each parameter is mapped to a **quality value in the range [0, 1]** using exponential functions derived from elasticity values.\n",
        "The **mode quality** is returned directly from a predefined mapping.\n",
        "\n",
        "All quality functions (including composite ones) may be modified as needed, provided:\n",
        "\n",
        "* Inputs remain unchanged\n",
        "* Outputs stay within **[0, 1]**\n",
        "\n",
        "---\n",
        "\n",
        "### Individual Quality Functions\n",
        "\n",
        "* **`headway_quality(headway)`** ‚Üí `[0,1]`\n",
        "* **`speed_quality(speed)`** ‚Üí `[0,1]`\n",
        "* **`walk_quality(distance)`** ‚Üí `[0,1]`\n",
        "* **`mode_quality(mode)`** ‚Üí `[0,1]`\n",
        "\n",
        "---\n",
        "\n",
        "### Composite Quality Functions\n",
        "\n",
        "#### Stop Quality\n",
        "\n",
        "* **Function:** `stop_quality(headway, mode, speed)`\n",
        "* **Output:** `[0,1]`\n",
        "\n",
        "Combines headway, mode, and speed qualities:\n",
        "\n",
        "$Q_{\\text{stop}} = f(Q_{\\text{headway}}, Q_{\\text{mode}}, Q_{\\text{speed}})$\n",
        "\n",
        "#### Access Quality (Final Quality)\n",
        "\n",
        "* **Function:** `access_quality(headway, mode, speed, distance)`\n",
        "* **Output:** `[0,1]`\n",
        "\n",
        "The access quality **must internally call**:\n",
        "\n",
        "* `stop_quality(headway, mode, speed)`\n",
        "* `walk_quality(distance)`\n",
        "\n",
        "$Q_{\\text{final}} = f(Q_{\\text{stop}}, Q_{\\text{distance}})$\n",
        "\n",
        "---\n",
        "\n",
        "This design ensures modularity while allowing flexibility in how individual and composite quality scores are computed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def headway_quality(headway):\n",
        "    return quality_utils.elasticity_based_quality(headway,min_headway,-headway_elasticity)\n",
        "\n",
        "def walk_quality(distance):\n",
        "    return quality_utils.elasticity_based_quality(distance,min_walk_distance,-walk_elasticity)\n",
        "\n",
        "def speed_quality(speed):\n",
        "    return quality_utils.elasticity_based_quality(speed,max_speed,speed_elasticity)\n",
        "\n",
        "def mode_quality(mode):\n",
        "    if isinstance(mode, str):\n",
        "        # single string\n",
        "        return mode_factor[mode]\n",
        "    else:\n",
        "        # convert to np.array if list\n",
        "        mode_arr = np.array(mode)\n",
        "        # vectorized lookup\n",
        "        vectorized_lookup = np.vectorize(lambda m: mode_factor[m])\n",
        "        return vectorized_lookup(mode_arr)\n",
        "\n",
        "def stop_quality(headway,mode,speed):\n",
        "    return (\n",
        "        headway_quality(headway) * \n",
        "        mode_quality(mode) *\n",
        "        speed_quality(speed)\n",
        "    )\n",
        "\n",
        "# Calibrate stop quality with the parameters defined in the beggining\n",
        "stop_quality = quality_utils.calibrate_quality_func(\n",
        "    stop_quality,\n",
        "    min_quality=1/n_accessibility_scores,\n",
        "    max_quality=1,\n",
        "    min_point=(worst_quality['headway'],worst_quality['mode'],worst_quality['speed']),\n",
        "    max_point=(best_quality['headway'],best_quality['mode'],best_quality['speed']),\n",
        ")\n",
        "\n",
        "def access_quality(headway,mode,speed,distance):\n",
        "    return (\n",
        "        stop_quality(headway,mode,speed) * \n",
        "        walk_quality(distance)\n",
        "    )\n",
        "\n",
        "# Calibrate access quality with the parameters defined in the beggining\n",
        "access_quality = quality_utils.calibrate_quality_func(\n",
        "    access_quality,\n",
        "    min_quality=1/n_accessibility_scores,\n",
        "    max_quality=1,\n",
        "    min_point=(worst_quality['headway'],worst_quality['mode'],worst_quality['speed'],worst_quality['distance']),\n",
        "    max_point=(best_quality['headway'],best_quality['mode'],best_quality['speed'],best_quality['distance']),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Discretization\n",
        "\n",
        "Build grids for fast numerical computations ensuring that the maximum quality change is less than 1/n_quality_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "headway_grid, mode_grid, speed_grid, distance_grid = quality_utils.build_adaptive_grids(\n",
        "    access_quality,\n",
        "    variables=[\n",
        "        [min_headway, max_headway],\n",
        "        list(simplified_route_type_mapping.keys()),\n",
        "        [min_speed, max_speed],\n",
        "        [min_walk_distance, max_walk_distance],\n",
        "    ],\n",
        "    delta=1/n_accessibility_scores\n",
        ")\n",
        "# Add 0 as the first speed in the speed grid\n",
        "# This avoids creating a grid at very low speeds but we still include all of them with the speed 0\n",
        "speed_grid = [0,*speed_grid] "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3 Public transport timetables\n",
        "\n",
        "### 3.1 Create the gtfs object\n",
        "\n",
        "This will do:\n",
        "\n",
        "- Load all .txt files of all gtfs folders given.\n",
        "\n",
        "- Select only the stops from `stops.txt` inside the area of interest.\n",
        "- Crop all trips in `stop_times.txt` with the stops inside the aoi + 1 more stop.\n",
        "- Check the `stop_sequence` in `stop_times.txt`.\n",
        "- Deal correctly with trips starting on one day and ending in the following day: hours always in 0-24 range but those trips are marked as `next_day` True. New `service_id`s are created to deal with that.\n",
        "- If the file has `frequencies.txt` this is processed too dealing with the next day problem.\n",
        "- If departure or arrival times are empty they get filled by interpolation.\n",
        "- A shape direction column is computed at each stop. (See documentation for details)\n",
        "- GTFS shapes are for now computed from the stop coordinates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# If you load too many feeds you might overflow your RAM \n",
        "gtfs = Feed(\n",
        "    file_paths,\n",
        "    aoi=aoi,\n",
        "    stop_group_distance=stop_group_distance,\n",
        "    start_date=start_date,\n",
        "    end_date=end_date,\n",
        "    check_files=False # Setting this to False could break but speeds processing up by a lot\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If there are **no services** in your date range you can always turn `start_date` and `end_date` to 'None' for the feed's `max` and `min` dates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Service Intensity\n",
        "\n",
        "The number of vehicles that arrive at each stop every day multiplied by the number of stops:\n",
        "\n",
        "$\\text{Service Intensity} = (\\text{Number of vehicles per stop}) \\times (\\text{Number of stops})$\n",
        "\n",
        "This is a fast way of seing how much service is offered every day in an approximate way"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "service_intensity = gtfs.get_service_intensity_in_date_range(\n",
        "    start_date=None, # If None take the feed min date\n",
        "    end_date=None, # If None take the feed max date\n",
        "    date_type=None, # Could be something like 'holiday', 'weekday', or 'monday' to only consider some dates from the range.\n",
        "    by_feed=True\n",
        ")\n",
        "service_intensity = service_intensity.to_pandas()\n",
        "gtfs_plot_helpers.service_intensity(service_intensity)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Select the most representative business day in a date range"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "idx = processing_helpers.most_frequent_row_index(service_intensity)\n",
        "selected_day = service_intensity.iloc[idx]['date'].to_pydatetime()\n",
        "selected_day"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3 Average speed\n",
        "\n",
        "Compute the average speed at stops.\n",
        "To compute speed distance is meassured at a fixed time difference of 'time_step' min from each stop\n",
        "\n",
        "<img src=\"https://github.com/CityScope/UrbanAccessAnalyzer/tree/main/examples/images/speed.jpg\" \n",
        "     alt=\"Speed computation\" \n",
        "     title=\"Speed computation\" \n",
        "     width=\"500\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Filter by the selected day and time bounds\n",
        "speed_by = \"trip_id\" \n",
        "stop_speed_lf = gtfs.get_speed_at_stops(\n",
        "    date=selected_day,\n",
        "    start_time=start_time,\n",
        "    end_time=end_time,\n",
        "    route_types = 'all',\n",
        "    by = speed_by, # Speed is computed for every 'trip_id' and grouped by this column with the how method\n",
        "    at = stop_id, # Compute speed for every 'parent_station' 'stop_id' or 'route_id'\n",
        "    how=\"mean\", # How to group individual trip speeds 'mean' 'max' or 'min'\n",
        "    direction='both', # Compute speed in 'forward' 'backward' or 'both' directions (walking n_stops in direction)\n",
        "    time_step=15, # Minutes required to meassure the speed\n",
        ")\n",
        "if isinstance(stop_speed_lf,pl.DataFrame):\n",
        "    stop_speed_lf = stop_speed_lf.lazy()\n",
        "\n",
        "# gtfs_lf will be used for later processing so we do not need to reprocess it\n",
        "gtfs_lf = gtfs.filter(\n",
        "        date=selected_day,\n",
        "        start_time=start_time,\n",
        "        end_time=end_time,\n",
        ")\n",
        "gtfs_lf = gtfs_lf.join(stop_speed_lf.select([stop_id,speed_by,'speed']),on=[stop_id,speed_by],how='left')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot an interactive map with stops and speeds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "m=None\n",
        "if show_maps:\n",
        "    # Group to speeds per stop and mode (or route_type) \n",
        "    best_stop_speed_lf = gtfs_lf.group_by(list(np.unique([\"route_type\", stop_id]))).agg(\n",
        "        pl.col(\"route_id\").unique().alias(\"route_ids\"),\n",
        "        (\n",
        "            (pl.col(\"speed\").abs() * pl.col(\"n_trips\")).sum()\n",
        "            / pl.col(\"n_trips\").sum()\n",
        "        ).alias(\"speed\"),\n",
        "        pl.col(\"n_trips\").sum().alias(\"n_trips\"),\n",
        "        pl.col(\"isin_aoi\").any().alias(\"isin_aoi\")\n",
        "    ).sort(\"speed\")\n",
        "    # Plot everythng on a map\n",
        "    best_stop_speed_df = best_stop_speed_lf.collect().to_pandas()\n",
        "    best_stop_speed_df = gtfs.add_stop_coords(best_stop_speed_df)\n",
        "    best_stop_speed_df = gtfs.add_route_names(best_stop_speed_df)\n",
        "    best_stop_speed_df = gpd.GeoDataFrame(\n",
        "        best_stop_speed_df,\n",
        "        geometry=gpd.points_from_xy(best_stop_speed_df['stop_lon'],y=best_stop_speed_df['stop_lat']),\n",
        "        crs=4326\n",
        "    )\n",
        "    m = plot_helpers.general_map(\n",
        "        aoi=aoi,\n",
        "        pois=best_stop_speed_df,\n",
        "        poi_cmap=\"RdYlGn\",\n",
        "        poi_column=\"speed\",\n",
        "    )\n",
        "    m.save(city_results_path+\"/stop_speed_map.html\")\n",
        "m"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.4 Average waiting time (headway) at stops\n",
        "\n",
        "headway is in *minutes*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this example we use the *shape_direction* mode \n",
        "\n",
        "- This groups all `trip_id`s at every `stop` by local shape direction.  \n",
        "\n",
        "- Creates 'n_divisions' * 2 groups (*2 to get outbound and inbound directions independently) by clustering the trip shape directions \n",
        "- If how = 'best' means the headway is computed only for the best of all divisions at every stop \n",
        "\n",
        "Local shape direction computation algorithm (1 division)\n",
        "\n",
        "<img src=\"https://github.com/CityScope/UrbanAccessAnalyzer/tree/main/examples/images/shape_grouping.jpg\" \n",
        "     alt=\"Local shape direction computation algorithm (1 division)\" \n",
        "     title=\"Local shape direction computation algorithm (1 division)\" \n",
        "     width=\"500\"/>\n",
        "\n",
        "Local shape direction computation algorithm (3 divisions)\n",
        "\n",
        "<img src=\"https://github.com/CityScope/UrbanAccessAnalyzer/tree/main/examples/images/shape_grouping_3_dirs.jpg\" \n",
        "     alt=\"Local shape direction computation algorithm (3 divisions)\" \n",
        "     title=\"Local shape direction computation algorithm (3 divisions)\" \n",
        "     width=\"500\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stop_headway_df = []\n",
        "for mode in mode_grid:\n",
        "    gtfs_selection = gtfs._filter_by_route_type(\n",
        "        gtfs_lf,\n",
        "        route_types=simplified_route_type_mapping[mode]\n",
        "    )\n",
        "    gtfs_length = (\n",
        "        gtfs_selection\n",
        "        .select(pl.len())\n",
        "        .collect()\n",
        "        .item()\n",
        "    )\n",
        "    if gtfs_length == 0:\n",
        "        continue \n",
        "\n",
        "    for i in range(len(speed_grid)-1):\n",
        "        gtfs_selection = gtfs_selection.filter(\n",
        "            (pl.col(\"speed\") >= speed_grid[i])\n",
        "        )\n",
        "        gtfs_length_i = (\n",
        "            gtfs_selection\n",
        "            .select(pl.len())\n",
        "            .collect()\n",
        "            .item()\n",
        "        )\n",
        "        if gtfs_length_i == gtfs_length:\n",
        "            continue \n",
        "        if gtfs_length_i == 0:\n",
        "            continue \n",
        "\n",
        "        gtfs_length = gtfs_length_i\n",
        "        df = gtfs._get_headway_at_stops(\n",
        "                gtfs_selection,\n",
        "                date=selected_day,\n",
        "                start_time=start_time,\n",
        "                end_time=end_time,\n",
        "                by = \"shape_direction\", # headway is computed for all 'trip_id' grouped by this column and sorted by 'departure_time'\n",
        "                at = stop_id, # Where to compute the headway 'stop_id' 'parent_station'\n",
        "                how = \"best\", \n",
        "                # 'best' pick the route with best headway, \n",
        "                # 'mean' Combine all headways of all routes, \n",
        "                # 'all' return results per stop and route\n",
        "                n_divisions=1, # Number of divisions for by = 'shape_direction'\n",
        "        ).with_columns(\n",
        "            pl.lit(mode).alias(\"mode\"),\n",
        "            pl.lit(speed_grid[i+1]).alias(\"speed_grid\")\n",
        "        )\n",
        "        stop_headway_df.append(df)\n",
        "\n",
        "stop_headway_df = (\n",
        "    pl.concat(stop_headway_df)\n",
        ").to_pandas()\n",
        "stop_headway_df[\"headway_grid\"] = np.array(headway_grid)[\n",
        "    np.searchsorted(np.array(headway_grid), stop_headway_df[\"headway\"], side=\"left\")\n",
        "]\n",
        "stop_headway_df = gtfs.add_stop_coords(stop_headway_df)\n",
        "stop_headway_df = gtfs.add_route_names(stop_headway_df)\n",
        "stop_headway_df = gpd.GeoDataFrame(\n",
        "    stop_headway_df,\n",
        "    geometry=gpd.points_from_xy(stop_headway_df['stop_lon'],y=stop_headway_df['stop_lat']),\n",
        "    crs=4326\n",
        ")\n",
        "stop_headway_df = stop_headway_df[stop_headway_df.geometry.is_valid]\n",
        "stop_headway_df[\"stop_quality\"] = stop_headway_df.apply(\n",
        "    lambda row: stop_quality(\n",
        "        row[\"headway\"],\n",
        "        row[\"mode\"],\n",
        "        row[\"speed_grid\"],\n",
        "    ),\n",
        "    axis=1\n",
        ")\n",
        "stop_headway_df[\"stop_quality_grid\"] = stop_headway_df.apply(\n",
        "    lambda row: stop_quality(\n",
        "        row[\"headway_grid\"],\n",
        "        row[\"mode\"],\n",
        "        row[\"speed_grid\"],\n",
        "    ),\n",
        "    axis=1\n",
        ").round(3)\n",
        "stop_headway_df = stop_headway_df.sort_values(\"stop_quality\").drop_duplicates(stop_id,keep=\"last\")\n",
        "stop_headway_df = stop_headway_df.sort_values(stop_id).reset_index(drop=True)\n",
        "stop_headway_df.to_file(os.path.join(city_results_path,\"stops.gpkg\"))\n",
        "stop_headway_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "m=None\n",
        "if show_maps:\n",
        "    m = plot_helpers.general_map(\n",
        "        aoi=aoi,\n",
        "        pois=stop_headway_df,\n",
        "        poi_cmap=\"Blues\",\n",
        "        poi_column=\"stop_quality\",\n",
        "    )\n",
        "    m.save(city_results_path+\"/stop_quality_map.html\")\n",
        "m"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nuEwUUBJL95"
      },
      "source": [
        "## 4 Street graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3fIPRqRJl8I"
      },
      "source": [
        "### 4.1 Regionwise file and cropping\n",
        "\n",
        "- Download best regionwise pbf file. (Covers a large area)\n",
        "\n",
        "- Crop it to cover our area of interest and save it in .osm format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXbIa5RFfipR"
      },
      "outputs": [],
      "source": [
        "osm_xml_file = os.path.normpath(city_results_path+f\"/streets.osm\")\n",
        "streets_graph_path = os.path.normpath(city_results_path+f\"/streets.graphml\")\n",
        "streets_path = os.path.normpath(city_results_path+f\"/streets.gpkg\")\n",
        "accessibility_streets_path = os.path.normpath(city_results_path+f\"/accessibility_streets.gpkg\")\n",
        "population_results_path = os.path.normpath(city_results_path+f\"/population.gpkg\")\n",
        "population_csv_results_path = os.path.normpath(city_results_path+f\"/population.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### OSMIUM\n",
        "\n",
        "To download the street network needed for the study online, the **osmium** tool is used.  \n",
        "It is only available for **Linux** and **Mac** (it works in Google Colab too).  \n",
        "\n",
        "To install, you can either:  \n",
        "\n",
        "- Visit [osmium-tool website](https://osmcode.org/osmium-tool/)  \n",
        "- Or run the command:  \n",
        "```bash\n",
        "  sudo apt-get install -y osmium-tool\n",
        "````\n",
        "\n",
        "Make sure it is added to your `PATH`.\n",
        "\n",
        "On **Windows**, you can use **conda-forge** to install it.\n",
        "\n",
        "```bash\n",
        "  conda install -c conda-forge osmium-tool\n",
        "````\n",
        "---\n",
        "\n",
        "To avoid using **osmium**, you can manually download the data:\n",
        "\n",
        "1. Go to [OpenStreetMap Export](https://www.openstreetmap.org/export#map=14/40.23633/-3.76084)\n",
        "2. Select the bounding box containing your area of interest.\n",
        "3. Click **Export**.\n",
        "4. Copy the `.osm` file that is downloaded to your project folder.\n",
        "5. Set the variable `osm_xml_file` to the path where the `.osm` file is located."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iy8p8QTCJN3S"
      },
      "outputs": [],
      "source": [
        "# Run only if osmium is installed \n",
        "\n",
        "# Select what type of street network you want to load\n",
        "network_filter = osm.osmium_network_filter(\"walk+bike+primary\")\n",
        "# Download the region pbf file crop it by aoi and convert to osm format\n",
        "osm.geofabrik_to_osm(\n",
        "    osm_xml_file,\n",
        "    input_file=results_path,\n",
        "    aoi=aoi_download,\n",
        "    osmium_filter_args=network_filter,\n",
        "    overwrite=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Manual download \n",
        "# osm_xml_file = \"path/to/file.osm\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jbfm-aezJ1Xr"
      },
      "source": [
        "### 4.2 Load to osmnx\n",
        "\n",
        "This way the street network is a networkx graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tN89ae27J1fo"
      },
      "outputs": [],
      "source": [
        "# Load\n",
        "G = ox.graph_from_xml(osm_xml_file)\n",
        "# Project geometry coordinates to UTM system to allow euclidean meassurements in meters (sorry americans)\n",
        "G = ox.project_graph(G,to_crs=aoi.estimate_utm_crs())\n",
        "# Save the graph in graphml format to avoid the slow loading process\n",
        "ox.save_graphml(G,streets_graph_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZaGCga3KFri"
      },
      "source": [
        "### 4.3 Simplify graph\n",
        "\n",
        "Edges with length smaler than X meters are deleted and its nodes merged"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GqUljLLMKDH9"
      },
      "outputs": [],
      "source": [
        "G = graph_processing.simplify_graph(G,min_edge_length=min_edge_length,min_edge_separation=min_edge_length*2,undirected=True)\n",
        "# Save the result in graphml format\n",
        "ox.save_graphml(G,streets_graph_path)\n",
        "\n",
        "street_edges = ox.graph_to_gdfs(G,nodes=False)\n",
        "street_edges = street_edges.to_crs(aoi.crs)\n",
        "street_edges.to_file(streets_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSN1C8j0KOt6"
      },
      "source": [
        "### 4.4 Add Points of interest to graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chOaFk5XKKn0"
      },
      "outputs": [],
      "source": [
        "G, osmids = graph_processing.add_points_to_graph(\n",
        "    stop_headway_df,\n",
        "    G,\n",
        "    max_dist=100+min_edge_length, # Maximum distance from point to graph edge to project the point\n",
        "    min_edge_length=min_edge_length # Minimum edge length after adding the new nodes\n",
        ")\n",
        "stop_headway_df['osmid'] = osmids # Add the ids of the nodes in the graph to points"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4X7gysEmKVkz"
      },
      "source": [
        "## 5 Compute isochrones\n",
        "\n",
        "This is the discretized matrix relating stop quality, distance and accessibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "distance_matrix = (\n",
        "    stop_headway_df\n",
        "    .apply(\n",
        "        lambda row: [\n",
        "            {\n",
        "                \"headway_grid\": row[\"headway_grid\"],\n",
        "                \"mode\": row[\"mode\"],\n",
        "                \"speed_grid\": row[\"speed_grid\"],\n",
        "                \"distance_grid\": d,\n",
        "                \"stop_quality_grid\": row[\"stop_quality_grid\"],\n",
        "                \"quality_grid\": access_quality(\n",
        "                    row[\"headway_grid\"],\n",
        "                    row[\"mode\"],\n",
        "                    row[\"speed_grid\"],\n",
        "                    d\n",
        "                )\n",
        "            }\n",
        "            for d in distance_grid\n",
        "        ],\n",
        "        axis=1\n",
        "    )\n",
        ")\n",
        "distance_matrix = (\n",
        "    distance_matrix\n",
        "    .explode()\n",
        "    .apply(pd.Series)\n",
        "    .drop_duplicates(['stop_quality_grid','distance_grid','quality_grid'])\n",
        "    .reset_index(drop=True)\n",
        ")\n",
        "quality_grid = np.linspace(0,1,n_accessibility_scores+1)\n",
        "idx = np.searchsorted(\n",
        "    quality_grid,\n",
        "    distance_matrix['quality_grid'],\n",
        "    side=\"left\"\n",
        ")\n",
        "idx = np.clip(idx, 0, len(quality_grid) - 1)\n",
        "distance_matrix['quality_grid'] = quality_grid[idx]\n",
        "distance_matrix['quality_grid'] = distance_matrix['quality_grid'].round(3)\n",
        "distance_matrix = distance_matrix.drop_duplicates(['stop_quality_grid','distance_grid','quality_grid'])\n",
        "distance_matrix = distance_matrix.reset_index(drop=True)\n",
        "distance_matrix = (\n",
        "    distance_matrix\n",
        "    .pivot(\n",
        "        index=\"stop_quality_grid\",\n",
        "        columns=\"distance_grid\",\n",
        "        values=\"quality_grid\"\n",
        "    )\n",
        "    .reset_index()\n",
        ")\n",
        "distance_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ueaNsEbzKVt6"
      },
      "outputs": [],
      "source": [
        "accessibility_graph = isochrones.graph(\n",
        "    G,\n",
        "    stop_headway_df,\n",
        "    distance_matrix,\n",
        "    poi_quality_col = 'stop_quality_grid', # If all points have the same quality this could be None\n",
        "    min_edge_length = min_edge_length # Do not add new nodes if there will be an edge with less than this length\n",
        ")\n",
        "# Save edges as gpkg\n",
        "accessibility_nodes, accessibility_edges = ox.graph_to_gdfs(accessibility_graph)\n",
        "accessibility_edges.to_file(accessibility_streets_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "520RVdd9KymW"
      },
      "source": [
        "#### Lets visualize the results on a map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.2 Convert to H3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "access_h3_df = h3_utils.from_gdf(\n",
        "    accessibility_edges,\n",
        "    resolution=h3_resolution,\n",
        "    columns=['accessibility'],\n",
        "    contain=\"overlap\",\n",
        "    method=\"max\",\n",
        "    buffer=10\n",
        ")\n",
        "\n",
        "access_h3_df.to_csv(city_results_path+\"/accessibility_h3.csv\")\n",
        "# The geodataframe takes much more space than csv as it converts h3 to polygons\n",
        "# If you do not need it comment it out\n",
        "access_h3_df = h3_utils.to_gdf(access_h3_df).to_crs(aoi.crs)\n",
        "access_h3_df.to_file(city_results_path+\"/accessibility_h3.gpkg\")\n",
        "access_h3_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "m=None\n",
        "if show_maps:\n",
        "    m = plot_helpers.general_map(\n",
        "        aoi=aoi,\n",
        "        pois=stop_headway_df,\n",
        "        gdfs=[access_h3_df,accessibility_edges],\n",
        "        cmap=\"RdYlGn\",\n",
        "        column=\"accessibility\",\n",
        "        poi_cmap=\"Blues\",\n",
        "        poi_column=\"stop_quality\"\n",
        "    )\n",
        "    m.save(city_results_path+\"/access_map.html\")\n",
        "m"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-r5ZpmgQK36t"
      },
      "source": [
        "## 6 Population"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OEorIvYLw1Q"
      },
      "source": [
        "### 6.1 Download Worldpop tif file\n",
        "\n",
        "- One file for every country\n",
        "- 100m pixel size\n",
        "- tif format\n",
        "- available from 2000 to 2030\n",
        "- gender and age"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "p5KvnaWVLoi5"
      },
      "outputs": [],
      "source": [
        "population_file = population.download_worldpop_population(\n",
        "    aoi_download,\n",
        "    2025,\n",
        "    folder=results_path,\n",
        "    resolution=\"100m\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pop_h3_df = h3_utils.from_raster(population_file,aoi=aoi_download,resolution=h3_resolution)\n",
        "pop_h3_df = pop_h3_df.rename(columns={'value':'population'})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJ0nB-JeMJZh"
      },
      "source": [
        "### 6.2 Assign level of service to each population cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results_h3_df = access_h3_df.merge(pop_h3_df,left_index=True,right_index=True,how='outer')\n",
        "results_h3_df.to_csv(population_csv_results_path)\n",
        "# The geodataframe takes much more space than csv as it converts h3 to polygons\n",
        "# If you do not need it comment it out\n",
        "results_h3_df = h3_utils.to_gdf(results_h3_df).to_crs(aoi.crs)\n",
        "results_h3_df = results_h3_df[results_h3_df.intersects(aoi.union_all())]\n",
        "results_h3_df.to_file(population_results_path)\n",
        "results_h3_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "m=None\n",
        "if show_maps:\n",
        "    pop_gdf_points = results_h3_df.copy()\n",
        "    pop_gdf_points.geometry = pop_gdf_points.geometry.centroid\n",
        "    pop_gdf_points = pop_gdf_points.dropna(subset=['population'])\n",
        "    pop_gdf_points = pop_gdf_points[pop_gdf_points['population'] > 1]\n",
        "    m = plot_helpers.general_map(\n",
        "        aoi=aoi,\n",
        "        pois=stop_headway_df,\n",
        "        gdfs=pop_gdf_points,\n",
        "        cmap=\"RdYlGn\",\n",
        "        column=\"accessibility\",\n",
        "        size_column=\"population\",\n",
        "        poi_column=\"stop_quality\",\n",
        "        poi_cmap=\"Blues\",\n",
        "    )\n",
        "    m.save(city_results_path+\"/population_map.html\")\n",
        "m"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Basic statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stats_df = results_h3_df.groupby('accessibility', as_index=False)['population'].sum()\n",
        "stats_df = stats_df.sort_values(\"accessibility\",ascending=False)\n",
        "total_population = stats_df['population'].sum()\n",
        "stats_df = pd.concat([stats_df, pd.DataFrame([{'accessibility': 'total population', 'population': total_population}])], ignore_index=True)\n",
        "stats_df['population %'] = (stats_df['population'] * 100 / total_population).round(2)\n",
        "stats_df['population'] = stats_df['population'].round(0).astype(int)\n",
        "stats_df.to_csv(city_results_path + \"/stats.csv\")\n",
        "stats_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !zip -r /content/output.zip \"{results_path}\" # For colab. Export the output folder as zip."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6kS_FEoDlft"
      },
      "source": [
        "Important files:\n",
        "\n",
        "- streets.gpkg Has the street geometry as lines (all streets)\n",
        "- accessibility_streets.gpkg Has the street geometry as lines with the level of service (only streets with level of service)\n",
        "- population.gpkg Is a grid with population and level of service\n",
        "- stats.csv Population statistics"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "urbanaccessanalyzer",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
