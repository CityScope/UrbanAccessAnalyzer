{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kEAwlkEGTsX"
      },
      "source": [
        "# Accessibility to public transport"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DgjJf1ryGRdB"
      },
      "outputs": [],
      "source": [
        "# If using colab\n",
        "# Takes around 2-3 min\n",
        "# !pip install \"UrbanAccessAnalyzer[osm,plot,h3] @ git+https://github.com/CityScope/UrbanAccessAnalyzer.git\"\n",
        "# !pip install matplotlib mapclassify folium\n",
        "# !apt-get install -y osmium-tool\n",
        "\n",
        "\n",
        "# Restart notebook after installing this if needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys \n",
        "sys.path.append('/home/miguel/Documents/Proyectos/PTLevelofService/gtfs/pyGTFSHandler')\n",
        "sys.path.append('/home/miguel/Documents/Proyectos/PTLevelofService/accessibility/UrbanAccessAnalyzer')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cuKHB4Q3GTL4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from datetime import datetime, date, timedelta, time\n",
        "import pandas as pd\n",
        "import polars as pl\n",
        "import geopandas as gpd\n",
        "import os\n",
        "\n",
        "import osmnx as ox\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import UrbanAccessAnalyzer.isochrones as isochrones\n",
        "import UrbanAccessAnalyzer.graph_processing as graph_processing\n",
        "import UrbanAccessAnalyzer.osm as osm\n",
        "import UrbanAccessAnalyzer.utils as utils\n",
        "import UrbanAccessAnalyzer.h3_utils as h3_utils\n",
        "import UrbanAccessAnalyzer.population as population\n",
        "\n",
        "from pyGTFSHandler.feed import Feed\n",
        "from pyGTFSHandler.downloaders.mobility_database import MobilityDatabaseClient\n",
        "import pyGTFSHandler.plot_helper as plot_helper\n",
        "import pyGTFSHandler.gtfs_checker as gtfs_checker\n",
        "import pyGTFSHandler.processing_helper as processing_helper\n",
        "\n",
        "import zipfile\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9YcUUo1GlAp"
      },
      "source": [
        "#### Results folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2YhNvRTkGfSg"
      },
      "outputs": [],
      "source": [
        "results_path = os.path.normpath(\"output\")\n",
        "os.makedirs(results_path,exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBsOw1Z4Gg3Q"
      },
      "source": [
        "## 1 Area of interest\n",
        "\n",
        "Area of interest (aoi): Polygon to do the analisys"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6AAqVIGdRcY"
      },
      "source": [
        "Option 1: Write the city name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cqxb76JEdFmp"
      },
      "outputs": [],
      "source": [
        "city_name = \"Parla, EspaÃ±a\"\n",
        "city_filename = utils.sanitize_filename(city_name)\n",
        "city_results_path = os.path.join(results_path,city_filename)\n",
        "os.makedirs(city_results_path,exist_ok=True)\n",
        "aoi = utils.get_city_geometry(city_name)\n",
        "geo_suggestions = utils.get_geographic_suggestions_from_string(city_name,user_agent=\"app\")\n",
        "geo_suggestions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nzsy8nghdsBv"
      },
      "source": [
        "Option 2: Load your own file (.gpkg or .shp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytEYIRZ-H7Zp"
      },
      "outputs": [],
      "source": [
        "# aoi = gpd.read_file(\"\")\n",
        "# city_name = \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8-aPZaxeJ03"
      },
      "source": [
        "Use UTM coords and creat aoi_download with a buffer of X meters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIv4dtOEH3f7"
      },
      "outputs": [],
      "source": [
        "aoi = gpd.GeoDataFrame(geometry=[aoi.union_all()],crs=aoi.crs) # Ensure there is only one polygon\n",
        "aoi = aoi.to_crs(aoi.estimate_utm_crs()) # Convert to utm\n",
        "\n",
        "aoi_download = aoi.buffer(2000) # Area to do streets and poi requests \n",
        "# It should be the maximum buffer we will use but there is the risk of downloading an area that is too large"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqdIui7uIl3u"
      },
      "source": [
        "Map of your area of interest and the download area (aoi_buffer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8xOffIHFIeNp"
      },
      "outputs": [],
      "source": [
        "m=aoi_download.explore(color='green')\n",
        "m=aoi.explore(m=m,color='red')\n",
        "m"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2 Public transport data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 Download GTFS feeds worldwide\n",
        "\n",
        "This example is for the MobilityData API\n",
        "\n",
        "This is the organization responsible for the GTFS standard and has info from almost all the world"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Request your refresh token here: https://mobilitydatabase.org/ \n",
        "refresh_token = 'AMf-vByYiwMAni1pw6yTpwgwwYFc8HR4y0zUKZGPT4sjJ0wUrIXOfVxF1KotRIvEgAseaaNheL8YczJiCILb6o2PUh-8zjA-qQURzEc8tELlwFiDopMoqJnkDf13AqNaGGnnzTDmYM20AWEquUxcYFAB8Q3e5rI2DcTBSQuiUdHL8bi48xmUJk3tayHpnoicoppi_evDcWYODwOJFcwnta3K7f718w7R2JRM0zDEOYw7nI7thrQa9462BENdpv8zv8mEbBssEa189k6YcV__sQAZlng2EcsCGA'\n",
        "api = MobilityDatabaseClient(refresh_token)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Find Feeds on the API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feeds = api.search_gtfs_feeds(\n",
        "    country_code=geo_suggestions['country_codes'],\n",
        "    subdivision_name=geo_suggestions['subdivision_names'], # This info is not always in the feeds metadata. Comment this if you did not find all feeds.\n",
        "    municipality=geo_suggestions['municipalities'], # This info is not always in the feeds metadata. Comment this if you did not find all feeds.\n",
        "    is_official=None, # Set to True if you only want official feeds\n",
        "    #aoi=aoi, # You could comment the rest of search args and use only aoi but for now the API seems to not do this very well as the metadata is often wrong.\n",
        ")\n",
        "\n",
        "for f in feeds:\n",
        "    print(f['provider'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Download current active files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gtfs_path = os.path.join(results_path,\"gtfs_files\") \n",
        "os.makedirs(gtfs_path,exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "file_paths = api.download_feeds(\n",
        "    feeds=feeds,\n",
        "    download_folder=gtfs_path,\n",
        "    overwrite=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Optional: Properly check all gtfs files for validity\n",
        "\n",
        "This takes a few minutes. If you skip the code will usually ignore wrong gtfs file rows without logging or solving it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Check and fix the gtfs files (This takes a few minutes). Set check_files = False in Feed to load faster\n",
        "\n",
        "# new_gtfs_path = os.path.join(results_path,\"revised_gtfs_files\") \n",
        "# os.makedirs(new_gtfs_path)\n",
        "\n",
        "# new_file_paths = []\n",
        "# for f in file_paths:\n",
        "#     filename = os.path.splitext(os.path.basename(f))[0]\n",
        "#     if os.path.isdir(os.path.join(new_gtfs_path,filename)):\n",
        "#         new_file_paths.append(os.path.join(new_gtfs_path,filename))\n",
        "#     else:\n",
        "#         new_file_paths.append(gtfs_checker.preprocess_gtfs(f,new_gtfs_path))\n",
        "\n",
        "# file_paths = new_file_paths"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 GTFS process\n",
        "\n",
        "#### 2.2.1 Create the gtfs object\n",
        "\n",
        "This will do:\n",
        "\n",
        "- Load all .txt files of all gtfs folders given.\n",
        "- Select only the stops from stops.txt inside the area of interest.\n",
        "- Crop all trips in stop_times.txt with the stops inside the aoi + 1 more stop.\n",
        "- Check the stop_sequence in stop_times.txt.\n",
        "- Deal correctly with trips starting on one day and ending in the following day: hours always in 0-24 range but those trips are marked as next_day True. New service_ids are created to deal with that.\n",
        "- If the file has frequencies.txt this is processed too dealing with the next day problem.\n",
        "- If departure or arrival times are empty they get filled.\n",
        "- A shape direction col is computed as the mean heading of the vector between stop coordinates to mean of the remainning stops coordinates.\n",
        "- GTFS shapes are for now computed from the stop coordinates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gtfs = Feed(\n",
        "    file_paths,\n",
        "    aoi=aoi,\n",
        "    stop_group_distance=100, # Group stops into one that are less than x meters apart. This creates or updates the parent_station column\n",
        "    start_date=datetime(day=1,month=11,year=2025),\n",
        "    end_date=datetime(day=1,month=1,year=2026),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2.2.2 Service Intensity\n",
        "\n",
        "This is the number of vehicles that arrive at each stop every day multiplied by the number of stops:\n",
        "\n",
        "$\\text{Service Intensity} = (\\text{Number of vehicles per stop}) \\times (\\text{Number of stops})$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "service_intensity = gtfs.get_service_intensity_in_date_range(\n",
        "    start_date=None, # If None take the feed min date\n",
        "    end_date=None, # If None take the feed max date\n",
        "    date_type=None, # Could be something like 'holiday', 'weekday', or 'monday' to only consider some dates from the range.\n",
        "    by_feed=True\n",
        ")\n",
        "service_intensity = service_intensity.to_pandas()\n",
        "plot_helper.plot_service_intensity(service_intensity)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Select the most representative business day in a date range"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "selected_service_intensity = gtfs.get_service_intensity_in_date_range(\n",
        "    start_date=None, # If None take the feed min date\n",
        "    end_date=None, # If None take the feed max date\n",
        "    date_type='businessday' # Could be something like 'holiday', 'businessday', 'non_businessday', or 'monday' to only consider some dates from the range.\n",
        ")\n",
        "selected_service_intensity = selected_service_intensity.to_pandas()\n",
        "idx = processing_helper.most_frequent_row_index(selected_service_intensity['service_intensity'])\n",
        "selected_day = selected_service_intensity.iloc[idx]['date'].to_pydatetime()\n",
        "selected_day"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2.2.3 Parameters, dates and times"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# date and time\n",
        "date = selected_day # date in this format date(year=2025,month=4,day=1)\n",
        "start_time = time(hour=8)\n",
        "end_time = time(hour=20)\n",
        "\n",
        "route_types = 'all' # Valid values are 'tram' 'subway' 'rail' 'bus' 'ferry' 'cable_car' 'gondola' 'funicular' \n",
        "# or any list combining those like ['rail', 'subway']\n",
        "\n",
        "stop_id = \"parent_station\" # Use the stop groups created with arg stop_group_distance in Feed to group neraby stops into one\n",
        "# You could choose 'stop_id' too"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2.2.4 Service quality\n",
        "\n",
        "Service quality is evaluated depending the route type and the mean frequency in the selected time interval.\n",
        "\n",
        "By default processing_helper.SERVICE_MATRIX to give grades"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Lets see what grade is given by default depending on route type and frequency.\n",
        "\n",
        "processing_helper.SERVICE_MATRIX # interval in minutes. The grading for stops is 1 for best - 12 for worst."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "simplified_route_type_mapping = {\n",
        "    'bus':'all',\n",
        "    'tram':[0,3,4,5,6,7],\n",
        "    'rail':[1,2]\n",
        "}\n",
        "\n",
        "# 0 - tram \n",
        "# 1 - subway \n",
        "# 2 - rail \n",
        "# 3 - bus\n",
        "# 4 - ferry \n",
        "# 5 - cable car \n",
        "# 6 - gondola \n",
        "# 7 - funicular\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2.2.4 Average waiting time (interval) at stops\n",
        "\n",
        "Interval is in *minutes*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this example we use the *shape_direction* mode \n",
        "\n",
        "- Uses direction (shape_direction) in degrees from north that every 'trip_id' is pointing to computed at every stop and every trip\n",
        "- Creates 'n_divisions' * 2 groups (*2 to get outbound and inbound directions independently) by clustering the trip shape directions \n",
        "- If how = 'best' means the interval is computed only for the best of all divisions at every stop "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stop_interval_df = []\n",
        "for simplified_route_type in simplified_route_type_mapping.keys():\n",
        "    route_types = simplified_route_type_mapping[simplified_route_type]\n",
        "    stop_interval_df.append(\n",
        "        gtfs.get_mean_interval_at_stops(\n",
        "            date=selected_day,\n",
        "            start_time=start_time,\n",
        "            end_time=end_time,\n",
        "            route_types=route_types, \n",
        "            by = \"shape_direction\", # Interval is computed for all 'trip_id' grouped by this column and sorted by 'departure_time'\n",
        "            at = stop_id, # Where to compute the interval 'stop_id' 'parent_station'\n",
        "            how = \"best\", \n",
        "            # 'best' pick the route with best interval, \n",
        "            # 'mean' Combine all intervals of all routes, \n",
        "            # 'all' return results per stop and route\n",
        "            n_divisions=1, # Number of divisions for by = 'shape_direction'\n",
        "        ).with_columns(pl.lit(simplified_route_type).alias(\"simplified_route_type\"))\n",
        "    )\n",
        "\n",
        "stop_interval_df = (\n",
        "    pl.concat(stop_interval_df)\n",
        ").to_pandas()\n",
        "stop_interval_df = gtfs.add_stop_coords(stop_interval_df)\n",
        "stop_interval_df = gtfs.add_route_names(stop_interval_df)\n",
        "stop_interval_df = gpd.GeoDataFrame(\n",
        "    stop_interval_df,\n",
        "    geometry=gpd.points_from_xy(stop_interval_df['stop_lon'],y=stop_interval_df['stop_lat']),\n",
        "    crs=4326\n",
        ")\n",
        "stop_interval_df = stop_interval_df[stop_interval_df.geometry.is_valid]\n",
        "stop_interval_df[\"service_quality\"] = stop_interval_df.apply(\n",
        "    lambda row: processing_helper.assign_service_quality_to_interval(\n",
        "        row[\"mean_interval\"],\n",
        "        row[\"simplified_route_type\"],\n",
        "        service_matrix=processing_helper.SERVICE_MATRIX\n",
        "    ),\n",
        "    axis=1\n",
        ")\n",
        "stop_interval_df = stop_interval_df.sort_values(\"service_quality\").drop_duplicates(stop_id,keep=\"first\")\n",
        "stop_interval_df = stop_interval_df.sort_values(stop_id).reset_index(drop=True)\n",
        "stop_interval_df.to_file(os.path.join(city_results_path,\"stops.gpkg\"))\n",
        "stop_interval_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "m = stop_interval_df[\n",
        "    [\n",
        "        stop_id,\n",
        "        \"mean_interval\",\n",
        "        \"service_quality\",\n",
        "        \"stop_name\",\n",
        "        \"route_names\",\n",
        "        \"route_type_texts\",\n",
        "        \"simplified_route_type\",\n",
        "        \"geometry\",\n",
        "    ]\n",
        "].explore(\n",
        "    column=f\"service_quality\",\n",
        "    cmap=\"Blues_r\",\n",
        "    vmin=1,\n",
        "    vmax=8,\n",
        "    style_kwds={\n",
        "        \"color\": \"black\",  # Border color\n",
        "        \"weight\": 1,  # Border thickness\n",
        "        \"opacity\": 1.0,  # Border opacity\n",
        "        \"fillOpacity\": 1,\n",
        "        \"radius\": 6,\n",
        "    },\n",
        ")\n",
        "m.save(city_results_path + \"/stops.html\")\n",
        "m"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nuEwUUBJL95"
      },
      "source": [
        "## 3 Street graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3fIPRqRJl8I"
      },
      "source": [
        "### 3.1 Regionwise file and cropping\n",
        "\n",
        "- Download best regionwise pbf file. (Covers a large area)\n",
        "\n",
        "- Crop it to cover our area of interest and save it in .osm format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXbIa5RFfipR"
      },
      "outputs": [],
      "source": [
        "osm_xml_file = os.path.normpath(city_results_path+f\"/streets.osm\")\n",
        "streets_graph_path = os.path.normpath(city_results_path+f\"/streets.graphml\")\n",
        "streets_path = os.path.normpath(city_results_path+f\"/streets.gpkg\")\n",
        "level_of_service_streets_path = os.path.normpath(city_results_path+f\"/level_of_service_streets.gpkg\")\n",
        "population_results_path = os.path.normpath(city_results_path+f\"/population.gpkg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iy8p8QTCJN3S"
      },
      "outputs": [],
      "source": [
        "# Select what type of street network you want to load\n",
        "network_filter = osm.osmium_network_filter(\"walk+bike+primary\")\n",
        "# Download the region pbf file crop it by aoi and convert to osm format\n",
        "osm.geofabrik_to_osm(\n",
        "    osm_xml_file,\n",
        "    input_file=results_path,\n",
        "    aoi=aoi_download,\n",
        "    osmium_filter_args=network_filter,\n",
        "    overwrite=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jbfm-aezJ1Xr"
      },
      "source": [
        "### 3.2 Load to osmnx\n",
        "\n",
        "This way the street network is a networkx graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tN89ae27J1fo"
      },
      "outputs": [],
      "source": [
        "# Load\n",
        "G = ox.graph_from_xml(osm_xml_file)\n",
        "# Project geometry coordinates to UTM system to allow euclidean meassurements in meters (sorry americans)\n",
        "G = ox.project_graph(G,to_crs=aoi.estimate_utm_crs())\n",
        "# Save the graph in graphml format to avoid the slow loading process\n",
        "ox.save_graphml(G,streets_graph_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZaGCga3KFri"
      },
      "source": [
        "### 3.3 Simplify graph\n",
        "\n",
        "Edges with length smaler than X meters are deleted and its nodes merged"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GqUljLLMKDH9"
      },
      "outputs": [],
      "source": [
        "min_edge_length = 30\n",
        "\n",
        "G = graph_processing.simplify_graph(G,min_edge_length=min_edge_length,min_edge_separation=min_edge_length*2,undirected=True)\n",
        "# Save the result in graphml format\n",
        "ox.save_graphml(G,streets_graph_path)\n",
        "\n",
        "street_edges = ox.graph_to_gdfs(G,nodes=False)\n",
        "street_edges = street_edges.to_crs(aoi.crs)\n",
        "street_edges.to_file(streets_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSN1C8j0KOt6"
      },
      "source": [
        "### 3.4 Add Points of interest to graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chOaFk5XKKn0"
      },
      "outputs": [],
      "source": [
        "G, osmids = graph_processing.add_points_to_graph(\n",
        "    stop_interval_df,\n",
        "    G,\n",
        "    max_dist=100+min_edge_length, # Maximum distance from point to graph edge to project the point\n",
        "    min_edge_length=min_edge_length # Minimum edge length after adding the new nodes\n",
        ")\n",
        "stop_interval_df['osmid'] = osmids # Add the ids of the nodes in the graph to points"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4X7gysEmKVkz"
      },
      "source": [
        "## 4 Compute isochrones\n",
        "\n",
        "### 4.1 Distance matrix\n",
        "\n",
        "We need a DISTANCE_MATRIX to relate level of service classes to service qualities and distance to the service.\n",
        "\n",
        "and we need a LEVEL_OF_SERIVCES list to order the level of services classes form best to worst (or leave it up to the code is the matrix is very symetric)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PApfLX3ckMMG"
      },
      "outputs": [],
      "source": [
        "distance_matrix = processing_helper.DISTANCE_MATRIX\n",
        "distance_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "level_of_services = processing_helper.LEVEL_OF_SERVICES\n",
        "level_of_services"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 Isochrones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ueaNsEbzKVt6"
      },
      "outputs": [],
      "source": [
        "level_of_service_graph = isochrones.graph(\n",
        "    G,\n",
        "    stop_interval_df,\n",
        "    distance_matrix,\n",
        "    service_quality_col = None, # If all points have the same quality this could be None\n",
        "    level_of_services = level_of_services, # could be None and it will set to the sorted unique values of the matrix\n",
        "    min_edge_length = min_edge_length # Do not add new nodes if there will be an edge with less than this length\n",
        ")\n",
        "# Save edges as gpkg\n",
        "level_of_service_nodes, level_of_service_edges = ox.graph_to_gdfs(level_of_service_graph)\n",
        "level_of_service_edges.to_file(level_of_service_streets_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "520RVdd9KymW"
      },
      "source": [
        "#### Lets visualize the results on a map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.3 Convert to H3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "h3_resolution = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ls_h3_df = h3_utils.from_gdf(\n",
        "    level_of_service_edges,\n",
        "    resolution=h3_resolution,\n",
        "    value_column='level_of_service',\n",
        "    value_order=level_of_services,\n",
        "    buffer=10\n",
        ")\n",
        "\n",
        "ls_h3_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "m = None\n",
        "\n",
        "# m = street_edges.explore(\n",
        "#     m = m,\n",
        "#     color='black'\n",
        "# )\n",
        "\n",
        "m = h3_utils.h3_to_gdf(ls_h3_df).explore(\n",
        "    m=m,\n",
        "    column='level_of_service',\n",
        "    cmap=\"RdYlGn_r\",\n",
        "    style_kwds={\n",
        "        \"color\": None,   # no border color\n",
        "        \"weight\": 0,     # border width\n",
        "        \"fillOpacity\": 0.3,  # optional fill transparency\n",
        "    }\n",
        ")\n",
        "\n",
        "m = level_of_service_edges.explore(\n",
        "    m=m,\n",
        "    column='level_of_service',\n",
        "    cmap=\"RdYlGn_r\",\n",
        "    style_kwds={\n",
        "        \"weight\": 3,        # thickness of the polygon/line border\n",
        "    }\n",
        ")\n",
        "\n",
        "m = stop_interval_df[\n",
        "    [\n",
        "        stop_id,\n",
        "        \"mean_interval\",\n",
        "        \"service_quality\",\n",
        "        \"stop_name\",\n",
        "        \"route_names\",\n",
        "        \"route_type_texts\",\n",
        "        \"simplified_route_type\",\n",
        "        \"geometry\",\n",
        "    ]\n",
        "].explore(\n",
        "    m=m,\n",
        "    column=f\"service_quality\",\n",
        "    cmap=\"Blues_r\",\n",
        "    vmin=1,\n",
        "    vmax=8,\n",
        "    style_kwds={\n",
        "        \"color\": \"black\",  # Border color\n",
        "        \"weight\": 1,  # Border thickness\n",
        "        \"opacity\": 1.0,  # Border opacity\n",
        "        \"fillOpacity\": 1,\n",
        "        \"radius\": 6,\n",
        "    },\n",
        ")\n",
        "m.save(city_results_path + \"/level_of_service.html\")\n",
        "m"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-r5ZpmgQK36t"
      },
      "source": [
        "## 5 Population"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OEorIvYLw1Q"
      },
      "source": [
        "### 5.1 Download Worldpop tif file\n",
        "\n",
        "- One file for every country\n",
        "- 100m pixel size\n",
        "- tif format\n",
        "- available from 2000 to 2030\n",
        "- gender and age"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "p5KvnaWVLoi5"
      },
      "outputs": [],
      "source": [
        "population_file = population.download_worldpop_population(\n",
        "    aoi_download,\n",
        "    2025,\n",
        "    folder=results_path,\n",
        "    resolution=\"100m\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pop_h3_df = h3_utils.from_raster(population_file,aoi=aoi_download,resolution=h3_resolution)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJ0nB-JeMJZh"
      },
      "source": [
        "### 5.2 Assign level of service to each population cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results_h3_df = ls_h3_df.merge(pop_h3_df,on='h3_cell',how='outer')\n",
        "results_h3_df = h3_utils.h3_to_gdf(results_h3_df).to_crs(aoi.crs)\n",
        "results_h3_df = results_h3_df[results_h3_df.intersects(aoi.union_all())]\n",
        "results_h3_df.to_file(population_results_path)\n",
        "results_h3_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sM2co6KQBbI3"
      },
      "outputs": [],
      "source": [
        "m = None\n",
        "\n",
        "# m = street_edges.explore(\n",
        "#     m = m,\n",
        "#     color='black'\n",
        "# )\n",
        "\n",
        "m = level_of_service_edges.explore(\n",
        "    m=m,\n",
        "    column='level_of_service',\n",
        "    cmap=\"RdYlGn_r\",\n",
        ")\n",
        "\n",
        "m = stop_interval_df[[\n",
        "    #\"name\",\n",
        "    \"geometry\"\n",
        "]].explore(\n",
        "    m=m,\n",
        "    color=\"green\",\n",
        "    style_kwds={\n",
        "        \"color\": \"black\",       # Border color\n",
        "        \"weight\": 1,            # Border thickness\n",
        "        \"opacity\": 1.0,         # Border opacity\n",
        "        \"fillOpacity\": 1,\n",
        "        \"radius\": 4,\n",
        "    },\n",
        ")\n",
        "\n",
        "pop_gdf_points = results_h3_df.copy()\n",
        "pop_gdf_points.geometry = pop_gdf_points.geometry.centroid\n",
        "pop_gdf_points = pop_gdf_points.dropna(subset=['population'])\n",
        "pop_gdf_points = pop_gdf_points[pop_gdf_points['population'] > 1]\n",
        "m=pop_gdf_points.explore(\n",
        "    m=m,\n",
        "    column=\"level_of_service\",            # color by service level\n",
        "    cmap=\"RdYlGn_r\",\n",
        "    legend=True,\n",
        "    tooltip=[\"population\", \"level_of_service\"],\n",
        "    marker_type=\"circle_marker\",\n",
        "    style_kwds={\n",
        "        # define a dynamic radius for each feature\n",
        "        \"style_function\": lambda x: {\n",
        "            \"radius\": (np.log1p(x[\"properties\"][\"population\"]) /\n",
        "                       np.log1p(pop_gdf_points[\"population\"].max()) * 5),\n",
        "            \"color\": \"black\",      # border color\n",
        "            \"weight\": 1,           # border thickness\n",
        "            \"opacity\": 1.0,        # border opacity\n",
        "            \"fillOpacity\": 1.0,    # fill opacity\n",
        "        },\n",
        "    },\n",
        ")\n",
        "m.save(city_results_path + \"/population.html\")\n",
        "import webbrowser \n",
        "webbrowser.open(city_results_path + \"/population.html\")\n",
        "m"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6kS_FEoDlft"
      },
      "source": [
        "Important files:\n",
        "\n",
        "- streets.gpkg Has the street geometry as lines (all streets)\n",
        "- level_of_service_streets.gpkg Has the street geometry as lines with the level of service (only streets with level of service)\n",
        "- population.gpkg Is a grid with population and level of service"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "urbanaccessanalyzer",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
